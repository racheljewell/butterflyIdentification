{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #to import data\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle   #unsure if you need this\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train/Training_set.csv')\n",
    "df_test = pd.read_csv('test/Testing_set.csv')\n",
    "df_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info(), df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info(), df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train[['filename']], df_test[['filename']]], axis='rows')\n",
    "df['label'] = [1]*len(df)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df_train['label_en'] = encoder.fit_transform(df_train['label'])\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target = []\n",
    "MAIN_FILE = 'notbutterfly/'\n",
    "for img in os.listdir(MAIN_FILE):\n",
    "    non_target.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target_labels = np.c_[non_target, [0]*len(non_target)]\n",
    "non_df = pd.DataFrame(non_target_labels, columns=['filename', 'label'])\n",
    "non_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_target = []\n",
    "IMAGE_SIZE = (40, 40)\n",
    "\n",
    "for img in non_df['filename']:\n",
    "    img = cv.imread('notbutterfly/' + img)\n",
    "    img = cv.resize(img, IMAGE_SIZE)\n",
    "    non_target.append(img/255.0)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=30,  # Rotate images by 30 degrees @ random\n",
    "    width_shift_range=0.2,  # Shift images horizontally 20% of total width @ random\n",
    "    height_shift_range=0.2,  # Shift images vertically 20% of total height @ random\n",
    "    shear_range=0.3,  # Apply shear transformation with a shear angle of 30 degrees\n",
    "    zoom_range=0.3,  # Zoom images by up to 30% @ random\n",
    "    horizontal_flip=True,  # Flip images horizontally @ random\n",
    "    vertical_flip=False  # Do not perform vertical flips\n",
    ")\n",
    "\n",
    "# grayscale numpy array of images \n",
    "images = non_target \n",
    "\n",
    "# Generate augmented grayscale images\n",
    "augmented_images = []\n",
    "\n",
    "for image in images:\n",
    "    num_generated_images = 0\n",
    "\n",
    "    while num_generated_images < 60:\n",
    "        augmented_image = datagen.random_transform(image)\n",
    "        augmented_images.append(augmented_image)\n",
    "        num_generated_images += 1\n",
    "\n",
    "# Convert augmented grayscale images back to a NumPy array\n",
    "augmented_images = np.array(augmented_images)\n",
    "non_target = np.squeeze(augmented_images)\n",
    "print(non_target.shape)\n",
    "plt.imshow(non_target[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (40,40)\n",
    "IMAGE_SIZE_CLASS = (60,60)\n",
    "\n",
    "train = []\n",
    "\n",
    "train_class = []\n",
    "train_labels = []\n",
    "\n",
    "test = []\n",
    "\n",
    "for img,label in zip(df_train['filename'], df_train['label_en']):\n",
    "    img = cv.imread('train/'+img)\n",
    "    det = cv.resize(img, IMAGE_SIZE)\n",
    "    clas = cv.resize(img, IMAGE_SIZE_CLASS)\n",
    "    train.append(det/255.0)\n",
    "    train_class.append(clas/255.0)\n",
    "    train_labels.append(label)\n",
    "\n",
    "for img in df_test['filename']:\n",
    "    img = cv.imread('test/' + img)\n",
    "    img = cv.resize(img, IMAGE_SIZE)\n",
    "    test.append(img/255.0)\n",
    "\n",
    "plt.imshow(train[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = list(train)+list(test)\n",
    "\n",
    "# Generate augmented images\n",
    "augmented_images_target = []\n",
    "for image in images:\n",
    "    num_generated_images = 0\n",
    "\n",
    "    while num_generated_images < 6:\n",
    "        augmented_image = datagen.random_transform(image)\n",
    "        augmented_images_target.append(augmented_image)\n",
    "        num_generated_images += 1\n",
    "\n",
    "augmented_images_target = np.array(augmented_images_target)\n",
    "target = np.squeeze(augmented_images_target)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(target)+ list(non_target))\n",
    "Y = np.array([1]*len(target)+[0]*len(list(non_target)))\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(40, 40, 3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=6, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensors = tf.convert_to_tensor(np.array(X_test))\n",
    "probabilities = model.predict(tensors)\n",
    "threshold = 0.3\n",
    "Y_pred = (probabilities > threshold).astype(int)[:,0]\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "plt.colorbar(cax)\n",
    "\n",
    "classes = np.unique(Y_test)\n",
    "ax.set_xticks(np.arange(len(classes)))\n",
    "ax.set_yticks(np.arange(len(classes)))\n",
    "ax.set_xticklabels(classes)\n",
    "ax.set_yticklabels(classes)\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    for j in range(len(classes)):\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center')\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(Y_test, Y_pred)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
